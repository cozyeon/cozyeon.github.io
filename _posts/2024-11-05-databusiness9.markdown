---
layout: post
title: "[데이터 분석가가 반드시 알아야 할 모든 것] 12. 통계 기반 분석 방법론"
date: 2023-11-05
categories: "데이터비지니스"
---

## **12-1. 분석 모델 개요**

### 통계 모델

- 통계학에 기반
- 학습 기반, 예측 목적
- 모형과 해석을 중요하게 생각, 오차와 불확정성 강조

![image.png](/assets/img/DB5/image.png)

### 기계 학습

- 인공지능에서 파생
- 학습 기반, 예측 목적
- 대용량 데이터를 활용하여 예측의 정확도를 높이는 것을 강조

![image.png](/assets/img/DB5/image1.png)

![image.png](/assets/img/DB5/image2.png)

→ 지도학습: 입력에 대한 정답이 주어져 출력된 결괏값과 정답 사이의 오차가 줄어들도록 학습과 모델 수정을 반복

→ 비지도학습(자율학습): 별도의 정답 없이 변수 간의 패턴을 파악하거나 데이터를 군집화

→ 강화학습: 모델의 결과에 보상과 벌을 주면서 스스로 학습하게 하는 것

## 12-2. 주성분 분석(PCA)

: 여러 개의 독립변수들을 잘 설명해 줄 수 있는 주된 성분을 추출하는 기법

### 차원을 감소하는 방법

1. 변수 선택을 통해 비교적 불필요하거나 유의성이 낮은 변수 제거
2. 변수들의 잠재적인 성분을 추출하여 차원을 줄이는 방법 
    
    → 주성분 분석, 공통요인분석(CFA)
    

<aside>
💡

차원의 저주: 변수가 늘어남에 따라 차원이 커지면서 분석을 위한 최소한의 필요 데이터 건수가 늘어나면서 예측이 불안정해지는 문제

</aside>

### 주성분 분석 조건

- 변수들이 등간 척도나 비율 척도로 측정한 양적변수여야 함
- 관측치들이 서로 독립적이고 정규분포를 이루고 있어야 함

### 주성분 분석 원리

![image.png](/assets/img/DB5/image3.png)

→ 해당 차원의 가장 많은 분선을 담아내는 축이 ‘주성분’이 됨. (3번 축)

![image.png](/assets/img/DB5/image4.png)

- 주성분을 찾는 과정은 각각의 포인트에서 축에 내린 지점과 원점 사이의 거리가 최대가 되도록 하는 축을 찾는 것
- 원점으로부터 각 포인트들의 지각 지점까지의 거리의 합이 가장 큰 축이 주성분이 됨.
- 처음 변수의 개수만큼 새로운 성분(축)이 나옴.

### 주성분의 설명력

![image.png](/assets/img/DB5/image5.png)

- 전체 분산 중에서 해당 주성분이 갖고 있는 분산
- 모든 포인트들과 주성분과의 거리의 제곱합을 n-1로 나누어 구함.

### 주성분 분석 실습

```python

```

## 12-2. 공통요인분석(CFA)

### 요인분석

- 탐색적 요인분석(EFA):  변수와 요인간의 관계가 사전에 정립되지 않거나 체계화되지 않은 상태에서 변수 간의 관계를 아랑보기 위해 사용
- 확인적 요인분석(CFA): 이미 변수들의 속성을 예상하고 있는 상태에서 실제로 구조가 그러한지 확인하기 위한 목적

### PCA vs. CFA

- 주성분분석(PCA): 요인분석을 하기 위해 전체 분산을 토대로 요인을 추출
    
    → 전체 변수를 가장 잘 설명해 주는 순으로 주성분의 우위 결정
    
- 공통요인분석(CFA): 요인분석을 하기 위해 공통분산만을 토대로 요인 추출
    
    → 공통분산만을 기반으로 요인을 추출하므로 주성분들간의 우위 개념 없음
    

### 요인분석 적합성 검증

: PCA나 CFA를 위해서는 우선 독립변수들 간의 상관성이 요인분석에 적합한지 검증해야 함. (바틀렛 테스트, KMO 검정)

**바틀렛(Bartlett) 테스트**

- 행렬식을 이용하여 카이제곱값을 구하여 각 변수들 사이의 상관계수의 적합성을 검증하는 방법
- 유의확률 p 값으로 나타냄
- p < 0.05 이면 변수들 간에 상관관계가 있으므로 분석에 적합

**KMO(Kaiser-Meyer-Olkin) 검정**

- 변수들 간의 상관관계가 다른 변수에 의해 잘 설명되는 정도를 나타내는 값을 통계적으로 산출하는 검정 방법
- 독립변수들 간의 상관계수 제곱들과 편상관계수들을 모두 더한 값에서 상관계수 제곱의 합이 차지하는 비율 값

![image.png](/assets/img/DB5/image6.png)

### 요인 개수 결정

- 적합성 검증 후에 주성분 변수들의 고유치를 확인하여 요인 개수 결정
- 고유치: 요인이 설명해 주는 분산의 양
    
    ⇒ 고유치가 1 이상인 요인만 선택, 총 분산의 60% 이상을 설명해 주는 요인까지 선정
    
    ![image.png](/assets/img/DB5/image7.png)
    
    → 2번 성분까지가 적정한 요인 수로 판단
    

- 엘보우 포인트: 그래프의 경사가 낮아지는 지점
    
    ⇒ 일반적으로 엘보우 포인트까지의 요인을 선택
    

![image.png](/assets/img/DB5/image8.png)

### 각 변수와 요인 간의 관계 파악

- 요인 적재 값을 통해 각 변수와 요인 간의 상관관계 정도 파악
- 요인 적재 값 ≥ ±0.3 → 변수와 요인에 유의성이 있음
- 요인 적재 값 ≥ ±0.5 → 해당 요인에서 중요한 변수

![image.png](/assets/img/DB5/image9.png)

### 공통요인분석 실습

```python

```

## 12-4. 다중공선성 해결과 섀플리 밸류 분석

### 다중공선성

: 독립변수들 간의 상관관계가 높은 현상

- 회귀분석의 전제 가정(독립 변수들은 서로 독립) 위반

### 다중공선성 판별 기준

1. 상관분석 - 상관계수의 절댓값 ≥ 0.7 → 상관성 높다고 판단
2. 결정계수와 t값 비교 - 결정계수는 크지만 t값이 낮을 때 다중공선성 의심
3. 분산팽창계수(VIF): 다른 독립 변수들이 해당 변수 대신 모델을 설명해 줄 수 있는 정도 - VIF≥5 → 다중공선성 의심 / VIF≥10 → 다중공선성 있다고 판단

![image.png](/assets/img/DB5/image10.png)

### 다중공선성 해결 방법

1. VIF값이 높으면서 종속변수와의 상관성(설명력)이 낮은 변수 제거
2. 표본 관측치를 추가적으로 확보
3. 로그, 표준화 등을 통한 변수 가공
4. 주성분분석을 통한 변수 축약
5. 변수 선택 알고리즘을 활용하여 적정 변수 자동 선정

## 12-5. 데이터 마사지와 블라인드 분석

**데이터 마사지**

: 데이터 분석 결과가 예상하거나 의도한 방향과 다를 때 데이터의 배열을 수정하거나 관점을 바꾸는 등 동일한 데이터라도 해석이 달라질 수 있도록 유도하는 것

- 편향된 데이터 전처리
- 매직그래프 사용 - 레이블 간격이나 비율을 왜곡하여 수치의 차이를 실제보다 크거나 작게 인식하도록 유도
- 분모 바꾸기 등 관점 변환
- 의도적인 데이터 누락 및 가공
- 머신러닝 모델의 파라미터 값 변경 및 연산반복
- 심슨의 역설

### 블라인드 분석

: 종속변수에 영향을 주는 독립변수들의 명칭과 의미를 감추고서 분석 모델을 수행하고 오직 결과치만 보고 그 의미를 해석

## 12-6. Z-test와 T-test

![image.png](/assets/img/DB5/image11.png)

### T-test

![image.png](/assets/img/DB5/image12.png)

![image.png](/assets/img/DB5/image13.png)

→ t통계량을 기각역 경계와 비교

### Z-test

![image.png](/assets/img/DB5/image14.png)

![image.png](/assets/img/DB5/image15.png)

### Z-test와 T-test 실습

```python

```

## 12-7. ANOVA(Analysis of Variance)

### ANOVA

- 세 집단 이상의 평균을 검정할 때 사용
- F분포 사용
- 독립변수 조건 - 범주형 변수 / 종속 변수 조건 - 연속형 변수

![image.png](/assets/img/DB5/image16.png)

![image.png](/assets/img/DB5/image17.png)

### ANOVA 실습

```python

```

## 12-8. 카이제곱 검정(교차분석)

### 카이제곱 검정

- 범주형 변수들 간의 연관성을 분석하기 위해 결합분포를 활용
- 연관성 정도를 수치로 표현할 수 없음
- 검정 통계량 카이 제곱을 통해 변수 간에 연관성이 없다는 귀무가설을 기각하는지 여부로 상관성 유무 판단
- 실체 관측빈도와 기대빈도와의 차이를 통해 상호독립성이나 관련성 분석

![image.png](/assets/img/DB5/image18.png)

![image.png](/assets/img/DB5/image19.png)

- 검정 통계량 값을 산출하여 유의수준에 따라 결정된 임계치를 비교하여 가설 검정

![image.png](/assets/img/DB5/image20.png)

![image.png](/assets/img/DB5/image21.png)

![image.png](/assets/img/DB5/image22.png)

![image.png](/assets/img/DB5/image23.png)

### 카이제곱 검정 실습

```python

```

## 13-1. 선형 회귀분석과 Elastic Net (예측모델)

### 선형 회귀분석 종류

- 단순 회귀분석 (단변량 회귀분석): 독립 변수 하나
- 다중 회귀 분석 (다변량 회귀분석): 독립 변수가 두 개 이상

### 선형 회귀분석 조건

- 독립변수 간에 상관관계가 없어야 함
- 잔차의 정규성: 독립변수에 해당되는 종속변수의 값들의 잔차는 정규분포를 따라야 함
- 잔차의 등분산성: 잔차의 분산은 회귀 모형의 독립 변숫값과 상관없이 일정해야 함
- 선형성: 독립변수 값의 변화에 따른 종속변수 값의 변화는 일정해야 함

### 다항 회귀

: 독립변수와 종속변수의 관계가 비선형 관계일 때 변수에 각 특성의 제곱을 추가하여 회귀선을 비선형으로 변환하는 모델

### 다항 회귀 결과 해석

![image.png](/assets/img/DB5/image24.png)

- Parameter Estimate: 각 변수의 계수
- Intercept: 절편, 종속변수의 기본 값
- Standard Error: 표준오차, 이 값을 클수록 예측값과 실젯값의 차이가 큼
- T Value
    - 노이즈 대비 시그널의 강도
    - 독립변수와 종속변수 간에 선형관계가 얼마나 강한지를 나타냄.
    - 계숫값/표준오차
    - 관측치의 크기에 따라 판단 기준이 달라짐 → P Value 이용
- P Value: T Value와 관측치 수에 의해 결정
- Tolerance(공차한계),VIF(분산팽창지수)
    - 해당 변수의 다른 독립 변수들과의 상관관계 수준을 판단
    - VIF=1/Tolerance

### 다항 회귀 변수 선택 방법

→ 분석가가 수동으로 일일이 변수 조합을 테스트 하는 것은 비효율적

- 전진 선택법: 절편만 있는 모델에서 시작하여 유의미한 독립변수 순으로 변수를 차례로 하나씩 추가하는 방법
- 후진 제거법: 모든 독립변수가 포함된 상태에서 시작하여 유의미하지 않는 순으로 설명변수 하나씩 제거하는 방법
- 단계적 선택법: 전진 선택법 + 후진 제거법, 처음에는 변수를 하나씩 추가하기 시작하면서 변수가 3개 이상이 되면 변수 추가와 젝를 번갈아 가며 수행
- LARS: 단계적 선택법 알고리즘을 개선한 방법
- 유전 알고리즘: 변수의 조합에 약간의 우연적 요소를 가미한 변화를 주어 기존 변수 조합과는 다른 새로운 변수의 조합을 탐색할 수 있는 방법
- Ridge, Lasso, Elastic Net: 변수 계수에 가중치를 주어 편향을 허용함으로써 예측 정밀도를 향상시킬 수 있는 방법

### Ridge, Lasso & Elastic Net

**Ridge**

- 전체 변수를 모두 유지하면서 각 변수의 계수 크기 조정
- 종속변수 예측에 영향을 거의 미치지 않는 변수는 0에 가까운 가중치를 줌
- 매개변수 ɑ값이 0이면 선형회귀와 동일, 값이 클수록 수평선 형태에 가까워 짐

**Lasso**

- 중요한 몇 개의 변수만 선택하고 나머지 변수들은 계수를 0으로 주어 영향력을 아예 없앰
- 매개변수 ɑ값을 통해 정규화 강도 조정

**Elastic Net**

- Ridge는 변환된 계수가 0이 될 수 없지만 Lasso는 0이 될 수 있다는 특성 결합
- Ridge와 Lasso의 혼합비율을 조정하여 모델의 성능을 최적으로 끌어냄
- 혼합비율이 0에 가까울수록 Ridge와 같아지고, 1에 가까울수록 Lasso와 같아짐
- 변수를 선별한 상태면 Ridge의 비율이 높이는 것이, 그렇지 않은 경우에는 Lasso의 비율을 높이는 것이 좋음

### 선형 회귀분석과 Elastic Net 실습

```python

```