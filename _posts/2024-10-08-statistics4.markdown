---
layout: post
title: "[통계101 데이터분석] Part 8,9"
date: 2023-10-08
categories: "데이터와통계학"
---

# 8장. 통계 모형화

## **8-1. 선형회귀 원리의 확장**

### **선형회귀는 다양한 해석 방법의 기초**
- 선형회귀: x를 설명변수, y를 반응변수로 하여 데이터에 1차식 y=a+bx를 적용하고 설명번수와 반응변수 사이의 관계를 밝히는 것   
-> but 실제 데이터 해석에서는 설명변수가 여러 개, 반응 변수가 범주형 번수인 경우 등 회귀모형 항상 적절 X
![from_linear](/assets/img/from_linear.jpg)


#### # 확장 방향성
1. 설명변수의 개수를 늘리거나 유형 변경하기
2. 반응변수의 유형 변경하기
3. 회귀모형의 형태 변경하기

### **다중회귀**
설명변수가 여러 개인 것

#### # 다중선형회귀모형
설명변수가 k개인 가장 단순한 모형    
![multi_linear](/assets/img/multi_linear.jpg)

- k+1 개의 파라미터를 가짐.
- a: 절편
- b<sub>i</sub>: 편회귀계수, x<sub>i</sub> 축에 대한 기울기
- 설명변수가 2개일 때의 회귀모형 -> 회귀평면

#### # 다중회귀 결과를 읽는 방법
![multi_linear_result](/assets/img/multi_linear_result.jpg)
- 편회귀계수는 모두 유의미
- R<sup>2</sup> : 데이터에 잘 들어맞는지를 나타냄
- F 통계량에서 얻은 p값 : 편회귀계수가 모두 0인 모형 (R<sup>2</sup>=0) 을 귀무가설로 하여 유의성 조사   
-> p<0.05 이므로 회귀모형의 설명력에 유의성이 있다고 판단.

### **편회귀계수**

#### # 표준화편회귀계수   
: 회귀분석을 시행하기 전에 각각의 설명변수를 평균 0, 표준편차 1로 변환한 다음, 회귀분석을 시행하여 구한 회귀계수 
- 각 설명변수가 표준편차 단위에서 1 늘었을 때 반응변수의 증감을 나타냄. 
- 회귀모형이 얼마나 잘 들어맞는지나 편회귀계수의 p값 등은 원래 회귀결과와 같음.

#### # why 표준화편회귀계수 이용??

- 회귀분석에서 구한 편회귀계수는 설명변수의 데이터 퍼짐 정도나 단위에 따라 크게 달라지기 때문에 편회귀계수끼리 비교할 수는 없음.   

- ex) [몸무게] = a + b<sub>1</sub> X [키] + b<sub>2</sub> X [ 1일 걸음 수 ] + 입실론   
    - b<sub>1</sub> : 키가 1cm 커질 때의 몸무게 증감   
    - b<sub>2</sub> : 1일 걸음 수가 1보 늘었을 때의 몸무게 증감   
    - 키 1cm가 하루에 1걸음 보다 훨씬 더 영향이 큼을 직관적으로 알 수 있음.   
    => 즉, 일반적인 편회귀계수끼리 그대로 비교할 수 없다.

![s_p_r_c](/assets/img/s_p_r_c.jpg)

#### # 편회귀계수의 해석
- 설명변수 사이에 상관이 있는 경우 x<sub>i</sub> 외의 설명변수를 고정한 채 x<sub>i</sub>를 독립적으로 움직일 수 없음.
- 상관계수가 1에 가까울 때, 다중공선성을 의심해 봐야 함.

### **범주형 변수를 설명변수로**
범주형을 회귀분석의 설명변수로 이용할 때 0또는 1과 같은 **가변수**를 이용
- 범주 2개 - 0 또는 1   
-> 기울기인 b가 두 범주의 차이를 나타냄.
- 범주 3개 이상 - 0 또는 1을 (범주개수 -1)개 준비    
 ex) 범주 4개 - (x1=0 x2=0 x3=0), (x1=1 x2=0 x3=0), (x1=0 x2=1 x3=0), (x1=0 x2=0 x3=1)   
 -> b가 (x1=0 x2=0 x3=0)에 해당하는 범주를 기준으로 그 밖의 범주들이 어느 정도 다른지 나타냄.    
 ![dummy_variable](/assets/img/dummy_variable.jpg)

### **공분산분석**
 : 일반적인 분산분석에 사용하는 데이터와 함께 양적 변수 데이터가 있는 경우에 후보가 되는 방법

 - 공변량(covariate): 새로 추가한 양적 변수   

ex) 회사원의 연소득 y가 회사 x<sub>i</sub>의 차이에 따라 달라지는지 조사   
![ANCOVA](/assets/img/ANCOVA.jpg)

?

### **고차원 데이터 문제**
- 차원의 저주: 차원이 늘어날수록 파라미터 추정에 필요한 데이터 양이 폭발적으로 증가함.
- 차원이 증가할수록 다중공선성 문제가 일어나기 쉬움. -> 모형의 추정 정밀도가 떨어짐.

### **다중공선성**
- 설명변수가 여러 개인 다중회귀에서 설명변수 사이에 강한 상관이 있는 경우 -> 다중공선성이 있다. 
- 다중공선성이 있다면 회귀계수의 추정오차가 커짐. -> 추정값의 신뢰성이 떨어짐.

#### # 다중공선성 측정
분산팽창인수 VIF(variance inflation factor) 계산      
![VIF](/assets/img/VIF.jpg)   
-> R<sub>i</sub><sup>2</sup> : 하나의 설명변수를 반응변수로 설정하고, 나머지 설명변수를 이용하여 회귀를 시행한 결정계수    
- VIF>10 : 2개 사이의 상관이 아주 강함.    
-> 서로 상관이 있는 2개 변수 중 하나를 없애거나, 차원 축소 방법을 이용하여 설명변수의 개수를 줄이는 것이 좋음. 


## **8-2. 회귀모형의 형태 바꾸기**

### **상호작용**
: 설명변수 간의 상승효과
- x<sub>i</sub> 가 1 증가했을 때의 y 증가 방식이 또 다른 설명변수의 영향을 받을 수도 있음. 
- 선형회귀모형 안에서 곱셈 c x<sub>i</sub> x<sub>j</sub> 로 도입 가능.   
![cxixj](/assets/img/cxixj.jpg)

#### # 상호작용항의 문제점
- 상호작용을 넣으면 해석이 어려워짐.
- 설명변수의 개수가 늘면 상호작용항의 수가 폭발적으로 늘어남.
- 상호작용의 형태는 다양한데도 곱셈으로만 나타냄.
- 설명변수와 상호작용항의 다중공선성 문제가 있음.

#### # 상호작용항을 적용하면 좋은 경우
- 상호작용이 있다는 것이 선행 연구에서 밝혀지거나 기대되는 때
- 데이터에 분명한 상호작용이 있을 때
- 상호작용 유무에 관심이 있을 때

### **이원배치 분산분석**
다원배치 분산분석: 여러 개의 요인을 동시에 고려하는 분산분석    
이원배치 분산분석: 2개의 요인을 고려하는 분산분석   

>ex) [줄기 길이] = 절편 + b<sub>1</sub> x<sub>1</sub>(비료없음0, 비료있음1) +  b<sub>2</sub> x<sub>2</sub>(저온0, 고온1) 
>-    
>- 비료 효과와 온도는 상관이 없음. but 실제로는 상관이 있을 수 있음.   
>- 상호작용항을 x2에 관해 정리하면 b2를 대신하여 (b<sub>2</sub> + c<sub>1</sub> x<sub>1</sub>)을 x2에 곱함.   
>-> x2가 저온에서 고온이 될 때의 줄기 길이는 비료 유무에 따라 달라짐.

- 가설검정 결과 상호작용항이 유의미하지 않다면 상호작용이 없다고 보고, 각각의 주효과를 그대로 평가

#### # 상호작용 패턴
![co_pattern](/assets/img/co_pattern.jpg)   
상호작용 X -> 기울기 평행


### **비선형회귀**
- 선형모형: 파라미터에 관해 선형   
> y = a + bx + cx<sup>2</sup>
>- x에 관해서는 2차식이므로 비선형
>- 파라미터에 관해서는 1차식인 선형이므로 선형모형



## **8-3. 일반화선형모형의 개념**

### **선형회귀 원리 확장하기**

- 일반화선형모형: 최소제곱법이 아닌 확률분포에 기반한 최대가능도 방법으로 회귀모형을 추정   
->일반화선형모형을 기초로 일반화선형혼합모형, 계층적베이지안 모형과 같은 유연한 모형화가 가능해짐.

- 통계 모형화: 데이터 성질을 고려하면서 확률 모형을 가정하고 파라미터를 추정하여 모형을 평가하는 일련의 작업
![model_model](/assets/img/model_model.jpg)

#### # 선형회귀가 적절하지 않은 상황
- 반응 변수가 값이 2개인 변수 (예/아니요)
- 반응 변수가 음이 아닌 정수
![linear_not_proper](/assets/img/linear_not_proper.jpg)

### **가능도와 최대가능도 방법**
선형회귀가 적절하지 않은 상황에서는 '확률적으로 얼마나 나타나기 쉬운가'에 기반해 데이터에 잘 들어맞는지 평가

- 가능도(우도, likelihood): 데이터 x에 대한 파라미터 θ의 함수   
-> 가능도가 크다 -> θ에서 얻은 데이터가 나타나기 쉬움.     
![P_x_theta](/assets/img/P_x_theta.jpg)   
![L_x_theta](/assets/img/L_x_theta.jpg)
- 최대가능도 방법 (최대가능도 추정): 가능도를 최대화하는 θ를 찾아, 이를 추정값으로 삼는 방법

#### # 그림으로 본 최대가능도 방법
![picture_logL](/assets/img/picture_logL.jpg)
- 이 세 경우에서 로그 가능도를 계산해 보면 =50일 때 가장 큰 값이 됨. 
- 이 세가지뿐만 아니라 다양한 값을 가지고 조사하면, =51.1에서 로그 가능도가 최대가 됨.

### **로지스틱 회귀**
범주 하나가 일어날 확률 p, 설명변수 x가 바뀌었을 때 p가 얼마나 달라지는지 조사.
![logistic_yp](/assets/img/logistic_yp.jpg)
-> a+bx 를 0~1로 바꾸는 역할을 함.   
-> 데이터 실현값은 0,1 이지만 반응변수는 연속값이 확률 p

#### # 로지스틱 함수
![logistic_function](/assets/img/logistic_funcion.jpg)
- a는 평행이동, b는 변화 정도를 나타냄.
- b의 절댓값이 클수록 급격하게 변화
- b의 부호는 로지스틱함수의 증가/감소 결정

로짓함수
![logit_funciton](/assets/img/logit_function.jpg)
- 좌변: 선형예측변수
- 연결함수: 선형예측변수와 반응변수의 확률분포 파라미터(p)를 잇는 함수   
=> 로지스틱 회귀의 연결함수는 로짓 함수이다.

#### # 오즈비
- 오즈: 어떤 사건이 일어날 확률 p와 일어나지 않을 확률 1-p의 비율 -> p/(1-p)
- 오즈비: 2개의 확률 p와 q에 대한 2개의 오즈 비율   
![OR](/assets/img/OR.jpg)   
-> OR>1 -> 확률 p가 q보다 일어나기 쉽다.

### **푸아송 회귀**
: 데이터가 음수가 되지 않는 정수일 때, 특히 반응변수가 개수일 때 고려해볼 수 있는 일반화선형모형
![poisson_regression](/assets/img/poisson_regression.jpg)

### **다양한 일반화선형모형**
![various_regression](/assets/img/various_regression.jpg)

#### # 과분산
: 분포에서 규정된 평균과 분산의 관계보다도 분산이 큰 경우   
-> 푸아송 회귀에서 문제가 될 경우 음이항 회귀로 대처

#### # 일반화선형혼합모형
서로 다른 장소에서 데이터를 얻는 상황에 이용

- 일반화선형모형
    - 설명변수 x, 선형예측변수 a+bx
- 일반화선형혼합모형
    - 설명변수 x, 선형예측변수 a+bx+r<sub>i</sub>
    - a,b: 고정효과
    - r<sub>i</sub>: 임의효과, 평균 0인 정규분포를 따름
    - 데이터 구조에 맞춘 유연한 모형화가 가능



## **8-4. 통계 모형의 평가와 비교**
### **왈드 검정**
왈드 통계량: 최대가능도 방법으로 얻은 추정값/표준오차   
왈드 검정: 최대가능도 추정량이 정규분포를 따른다고 가정했을 때, 왈드 통계량을 이용하여 신뢰구간이나 p값을 얻는 검정 방법

### **가능도비 검정**
- 조건: 2개의 모형 중 어느 한쪽이 다른 한쪽을 포함하는 관계여야 함.
- 귀무가설: y=a, 대립가설: y=a+bx
- 검정통계량: -2 (logL<sub>1</sub> - logL<sub>2</sub>)
- 검정통계량 값이 클수록 데이터가 잘 들어맞도록 개선되었음을 의미.

### AIC(아카이케 정보기준, Akaike information criterion)
: 새롭게 얻을 데이터를 얼마나 잘 예측할 수 있는지를 바탕으로 모형의 적합도를 결정하는 지표   
- AIC = -2logL + 2k   
-> 최대가능도 L, 모형의 파라미터 개수 k
- 후보 모형 중 AIC를 최소화하는 모형을 좋은 모형으로 선택
- 실제 데이터에 잘 들어맞는지와 모형의 파라미터 개수를 고려하여 모형 평가함으로써 과대적합이 없는 모형을 선택하는 지표

### BIC(베이즈 정보기준, Bayesian information criterion)
- BIC = -2logL + klog(n)    
-> 최대가능도 L, 파라미터 개수k, 표본크기 n
- 후보 모형 중 BIC를 최소화하는 모형을 좋은 모형으로 선택
- 표본크기 n이 클수록 파라미터 개수 k의 페널티가 커짐.

### 그 밖의 정보기준
- AICc: AIC를 보정해 표본크기가 작을 때 사용
- DIC: 최대가능도 방법이 아닌 베이즈 추정으로 얻은 모형을 대상으로한 편차정보기준
- WAIC, WBIC: 계층적 베이지안 모형이나 관찰할 수 없는 변수를 포함하는 모형일 때 사용




# 9장. 가설검정의 주의점

## **9-1. 재현성**

### **가설검정, 이해는 어렵지만 시행은 간단**

- 재현성: 누가 언제 어디서 실험하더라도, 조건이 동일하다면 동일한 결과를 얻을 수 있어야 한다.
- 재현성 위기: 재현성이 없다. = 원래 논문의 주장이 잘못되었을 가능성이 있다.

#### # 과학에서의 재현성
- 새롭게 개발한 약의 효과나 부작용을 조사하는 실험에 재현성이 있기에 비로소 안심하고 약을 복용하거나 효과를 기대할 수 있음.
- but 최근 논문으로 발표된 내용을 다른 연구자가 추시했을 때 같은 결과를 얻지 못했다는 보고 잇따름.

#### # 심리학에서의 재현성 위기
- 심리학 분야에서 보고된 과거 연구 100건을 추시한 결과 원래 연구에서는 97%가 유의미하다고 한 데 비해 추시에서는 36%만 유의미한 것으로 나타남.

### **재현 불가능한 원인은?**
- 실험 조건을 동일하게 조성하기 어려움.
- p-해킹: 연구자가 자신에게 유리하도록 p값을 조작하는 행위

### **과학 논문 게재 과정**
- 논문 출판에서는 통계적으로 유의미한 결과 (p<0.05)를 얻지 못한 경우 게재가 거절될 때가 흔함.
-> 출판 편향 문제를 일으킴.
- 출판 편향: p>= 0.05 인 결과는 세상에 나오지 못하게 함으로써, 출판된 내용에 치우침이 생김.

## **9-2. 가설검정의 문제점**

### **p값 되돌아보기**
- p-value: 귀무가설이 옳다고 가정할 때 실제 관찰한 데이터 이상으로 극단적인 값을 얻을 확률
- 일반적으로 α=0.05을 이용하므로 귀무가설이 옳더라도 평균 20번에 1번꼴로 p<α가 될 수 있음.

#### # 왜 α=0.05를 사용하는가?
- α=0.05로 얻은 통계적으로 유의미한 결과 중, 실제로 귀무가설이 옳았을 비율이 뜻밖에 높음.
- but 유의수준 α와 제 2종 오류가 일어날 확률 β는 서로 상충 관계에 있음. -> α를 작게 하면 β는 커짐.

### **피셔류 검정과 네이만 - 피어슨류 검정**
- 피서류 검정: 귀무가설이 옳을 때 관찰한 데이터 이상으로 극단적인 값을 얻을 확률인 p값을 계산하고, 귀무가설과 관찰한 값의 괴리 정도를 평가.   
-> 가설 기각 개념 X, p값의 크기에 따라 증거의 강력함을 평가
- 네이만-피어슨류 검정: p값이 유의수준 α 미만인가 이상인가에만 주목하여 가설 기각/채택   
-> 설정한 α와 β에 따라 n을 결정해야 함. but 관찰 연구의 경우 n이 이미 결정되어 있음.

#### # 표본크기 n 정하기
- 표본크기 n은 데이터를 얻기 전에 미리 설계해 두어야 함.
- 가설검정에서 유의수준 α, 검정력 1-β , 효과크기, 표본크기 n은 이 중 셋을 결정하면 나머지 하나는 자동으로 정해짐.
- 통계 소프트웨어를 사용하여 계산

#### # 표본크기 n과 p값
![n_p](/assets/img/n_p.jpg)   
- 표본크기 n이 클수록 아주 약간의 차이로도 p=0.01이 될 수 있음.
- p값은 차이의 크기뿐만 아니라 표본크기 n에도 의존함.   

![n_p_2](/assets/img/n_p_2.jpg)
- 표본크기에 따라 가설검정의 결과가 달라짐.
- 검정력 0.8에 필요한 표본크기 17임을 확인할 수 있음.
     

=> 표본크기 n이 커지면 p값은 작아지므로 검출하고자 하는 효과크기를 사전에 설정하고 표본크기 n을 설계해야 함.

### **효과크기**
: 얼마만큼의 효과가 있는지를 나타냄.
- Cohen's d: 2개 집단 평균값 차이의 효과크기   
-> 데이터 값 그 자체에 의존하지 않도록, 모집단의 분산으로 표준화하여 평균값의 차이를 이해하고자 하는 지표   
ex) 평균값 차이는 10 -> 큰거야 작은거야?    
![cohens_d](/assets/img/cohens_d.jpg)
![cohens_d_2](/assets/img/cohens_d_2.jpg)

#### # 다양한 효과크기
현대 통계 해석에서는 p값만을 보고하는 것이 아니라 효과 크기도 함께 나타내는 것이 주류임.
![effectsize](/assets/img/effectsize.jpg)

### **베이즈 인수**
p>=0.05 일 때는 귀무가설을 지지하는 것이 아니라 판단을 보류함.    
-> 이 문제를 해결하기 위해 p값 대신 베이즈 인수 사용

- 주변가능도(에비던스)
    - 어떤 모형(가설) M이 얻은 데이터 x를 설명하는 데 얼마나 적절한지 나타냄.
    - 얻은 데이터 x 에 대한 모형 M의 평균 예측력
    - 이 값이 클수록 모형 M이 데이터 x를 잘 설명할 수 있음을 나타냄.
    ![p_xM](/assets/img/p_xM.jpg)

- 베이즈 인수
    - 1보다 클 때 - M1이 더 적합
    - 이 기준과 관련하여 여러 의견이 존재. 
    - 2.5~3.4(약한증거) -> α=0.05 / 14~26(강한 증거) -> α=0.005
![bayes](/assets/img/bayes.jpg)

#### # 베이즈 인수의 특징과 주의점
특징   
- 귀무가설과 대립가설을 대등하게 비교할 수 있으며, 귀무가설을 지지할 수도 있음.
- 베이즈 인수가 특정 값이 될 때까지 표본크기 n을 늘린다는 순차적인 갱신 가능.
- 2개 모형을 비교할 때 실제 모형이 포함되어 있다면 표본크기가 무한대로 커질 때 실제 모형을 고를 확률이 1에 한없이 가까워짐. -> 좋은 지표

주의할점
- 두 가설의 상대적인 비교일 뿐이어서 한쪽 가설이 나쁜 것만으로 베이즈 인수가 큰 값이 될 수 있음.
- 파라미터 θ의 사전분포에 영향을 받음.
- 주변 가능도를 구할 때 적분 계산이 필요하므로 베이즈 인수를 계산하는 데 시간과 노력이 필요.

### **논문이 옳지 않을 확률**

![Q_FDR](/assets/img/Q_FDR.jpg)

- 허위발견율(FDR, false discovery rate): 옳다고 주장된 것 중 위양성인 것의 비율   
-> 높은 FDR은 재현성 저하로 직결, 가능한 한 작은 것이 바람직함.

- Q: 세운 가설이 옳을 확률 / 유의수준 α / 검정력 1-β   
=> 가설검정에서는 좋은 가설을 세우는 것이 매우 중요함.

### **좋은 가설 세우기**
좋은 가설 = 진실을 말하는 가설   
-> 황당무계한 가설이라도 여러 가설을 세워 검정하다 보면, 어쩌다 p<0.05가 되어 얼핏 효과가 있는 것처럼 보이게 되고, FDR은 상승함.

## **9-3. p-해킹**

### **p-해킹이란?**
의도하든, 의도하지 않든 p값을 원하는 방향으로 (p<0.05) 조작하는 행위

구체적인 사례
1. p<0.05 가 될 때까지 표본크기 n을 늘림
2. 처음에는 n=30으로 실험하여 p<0.07 이었지만, 표본크기 n=10을 추가하여 n=40으로 실험했더니 p<0.05가 되었길래 이를 보고함
3. 여러 개의 요인을 탐색하여 그 중 p<0.05 인 것만 보고함


#### # 결과를 보며 표본크기를 늘려서는 안 됨
표본크기 n을 늘려 가다 보면 적어도 1번은 p<0.05가 되는 확률이 0.05보다도 커지기 때문   
![p_n_increase](/assets/img/p_n_increase.jpg)

#### # 마음에 드는 해석만 보고해서는 안 됨

HARKing: Hypothesis After the Results are Known, 데이터를 얻어 결과를 보고 나서 가설을 만드는 행위   
-> 의미 없는 데이터를 많이 모으다 보면 어쩌다 의미가 있어 보이는 결과를 얻을 수도 있기 때문   
ex) 신약 A,B,C,D... 의 효과를 조사 -> 효과가 있다고 발견된 신약으로 가설검정    
![HARKing](/assets/img/HARKing.jpg)

### **p-해킹을 예방하기 위한 노력들**

#### # 가설검증형 연구와 탐색형 연구
- 탐색형 연구: 전체를 탐색적으로 해석하는 연구   
- 가설검증형 연구: 가설을 세우고 이를 검증하는 연구   
-> 가설검증형 연구에 따라 올바르게 가설검정을 사용해야 함.   
-> 탐색형 연구밖에 할 수 없다면 실험이나 해석에 사용한 변수를 모두 보고하고 본페로니 교정으로 보정해야 함.

#### # 사전 등록
: 연구를 실시하기 전에 가설과 실험 설계, 분석 방법 등의 연구 계획을 등록하는 것   
-> HARKing 을 막을 수 있음.

#### # p값 관련 문제 정리
- p값을 제대로 이해하고 사용한다.
- 가설검정을 반복하면 다중성 문제가 반복하고, 위양성이 증가한다는 것을 이해한다.
- 탐색형 연구와 가설검증형 연구의 차이를 이해한다.
- 실시한 실험이나 해석은 제대로 보고한다.
- 재현성이 있는지 염두에 둔다. 가능하다면 재실험하여 확인한다.
- 좋은 가설을 세운다.

### **가설검정을 이해할 때 확인할 항목**

가설검정에 대해 자주 오해하는 지점
- p값이란 귀무가설이 옳을 확률을 말한다.
- p값이란 우연만으로 관찰 데이터가 나타날 확률이다. 
- 유의미한 결과란 귀무가설이 틀리다는 뜻이다.
- 유의미가 아닌 결과란 귀무가설이 옳다, 또는 귀무가설을 채택해야 한다는 의미이다.
- p값이 클수록 귀무가설을 지지한다는 증거이다.
- p>=0.05는 효과가 없음을 관찰했다, 또는 귀무가설을 채택해야 한다는 의미이다.
- 통계적으로 유의미하다는 것은 과학적으로 매우 중요한 관계를 밝혔다는 것을 뜻한다.
- 통계적으로 유의미하지 않다면 효과크기가 작다는 뜻이다.
- p값이란 귀무가설이 옳을 때 데이터가 우연히 나타날 확률을 뜻한다.
- p<0.05이므로 귀무가설을 기각했다. 이때 위양성 확률은 5%이다.   
-> 귀무가설이 옳음에도 이를 기각한다면 위양성 확률은 100%다.
- p값은 부등호로 나타내는 것이 올바르다.
- 통계적 유의성은 조사하고자 하는 현상을 설명하는 성질이므로, 검정에 의해 현상의 의미를 발견할 수 있다.






   